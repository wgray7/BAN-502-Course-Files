---
title: "Random Forest Quiz"
output: word_document
date: "2024-09-23"
---

Libraries
```{r}
library(tidyverse)
library(tidymodels)
library(caret)
library(gridExtra)
library(vip)
library(ranger)
```

#Read in Data
```{r}
drug = read_csv("drug_data-2.csv")
```
#Apply Names to columns
```{r}
names(drug)=c("ID","Age","Gender","Education","Country","Ethnicity","Nscore","Escore","Oscore","Ascore","Cscore","Impulsive","SS","Alcohol","Amphet","Amyl","Benzos","Caff","Cannabis","Choc","Coke","Crack","Ecstasy","Heroin","Ketamine","Legalh","LSD","Meth","Mushrooms","Nicotine","Semer","VSA")
```

#Next-up we change all CL0 and CL1 values to “No” and CL2, CL3, CL4, CL5, and CL6 values to “Yes”.
```{r}
drug[drug=="CL0"]="No"
drug[drug=="CL1"]="No"
drug[drug=="CL2"]="Yes"
drug[drug=="CL3"]="Yes"
drug[drug=="CL4"]="Yes"
drug[drug=="CL5"]="Yes"
drug[drug=="CL6"]="Yes"
```

#Factor Conversion 
```{r}
drug_clean=drug%>%mutate_at(vars(Age:Ethnicity),funs(as_factor))%>%mutate(Age =factor(Age,labels =c("18_24","25_34","35_44","45_54","55_64","65_")))%>%mutate(Gender =factor(Gender,labels =c("Male","Female")))%>%mutate(Education =factor(Education,labels =c("Under16","At16","At17","At18","SomeCollege","ProfessionalCert","Bachelors","Masters","Doctorate")))%>%mutate(Country =factor(Country,labels =c("USA","NewZealand","Other","Australia","Ireland","Canada","UK")))%>%mutate(Ethnicity =factor(Ethnicity,labels =c("Black","Asian","White","White/Black","Other","White/Asian","Black/Asian")))%>%mutate_at(vars(Alcohol:VSA),funs(as_factor))%>%select(-ID)
```
```{r}
str(drug_clean)
```
#Remove variables 
```{r}
drug_clean=drug_clean%>%select(!(Alcohol:Mushrooms))%>%select(!(Semer:VSA))
```

#Question 1 
Check for missing data in our "drug_clean" dataframe.
```{r}
skim(drug_clean)
summary(drug_clean)
str(drug_clean)
```

True or **False**: There is missing data

#Question 2
Split the dataset into training (70%) and Testing (30%) sets. Use set 1234. Stratify by the "Nicotine" variable
```{r}
set.seed(1234) 
drug_split = initial_split(drug_clean, prop = 0.7, strata = Nicotine) #70% in training
train = training(drug_split)
test = testing(drug_split)
```
How many rows are in Training Set? 
**1318**

#Question 3
Create appropriate visualizations (12 in all) to examine the relationships between each variable and “Nicotine”. Use grid.arrange (from the gridExtra package) to organize these visuals (perhaps in groups of four visualizations?)

#Visualization
```{r}
p1 = ggplot(train, aes(x = Age, fill = Nicotine)) + geom_bar(position = "fill")+
  theme(axis.text.x = element_text(angle = 90,vjust = 0.5, hjust = 1))
p2 = ggplot(train, aes(x = Gender, fill = Nicotine)) + geom_bar(position = "fill")
p3 = ggplot(train, aes(x = Education, fill = Nicotine)) + geom_bar(position = "fill")+
  theme(axis.text.x = element_text(angle = 90,vjust = 0.5, hjust = 1))
p4 = ggplot(train, aes(x = Country, fill = Nicotine)) + geom_bar(position = "fill")+
  theme(axis.text.x = element_text(angle = 90,vjust = 0.5, hjust = 1))
P5 = ggplot(train, aes(x = Ethnicity, fill = Nicotine)) + geom_bar(position = "fill")
grid.arrange(p1,p2,p3,p4)
```
```{r}

p1 = ggplot(train, aes(x = Nicotine, y = Nscore)) + geom_boxplot()
p2 = ggplot(train, aes(x = Nicotine, y = Escore)) + geom_boxplot()
p3 = ggplot(train, aes(x = Nicotine, y = Oscore)) + geom_boxplot()
p4 = ggplot(train, aes(x = Nicotine, y = Ascore)) + geom_boxplot()
grid.arrange(p1,p2,p3,p4, ncol = 2)

```

```{r}
p1 = ggplot(train, aes(x = Ethnicity, fill = Nicotine)) + geom_bar(position = "fill")+
  theme(axis.text.x = element_text(angle = 90,vjust = 0.5, hjust = 1))
p2 = ggplot(train, aes(x = Nicotine, y = Cscore)) + geom_boxplot()
p3 = ggplot(train, aes(x = Nicotine, y = Impulsive)) + geom_boxplot()
p4 = ggplot(train, aes(x = Nicotine, y = SS)) + geom_boxplot()
grid.arrange(p1,p2,p3,p4, ncol = 2)
```
#True/False: Individuals in the 18-24 age group are proportionally more likely to be Nicotine users than not.
**False**

#Question 4
**True**/False: Individuals with higher “Impulsive” scores more likely to be Nicotine users than not.
True

#Question 5
Create a random forest model (using the ranger package) on the training set to predict Nicotine using all of the variables in the dataset. You 5-fold, k-fold cross-validation (random number seed of 123 for the folds). 
```{r}
set.seed(234)
rf_folds = vfold_cv(train, v = 5)
```

```{r}


Nicotine_recipe = recipe(Nicotine ~., train) %>%
  step_dummy(all_nominal(), -all_outcomes())

rf_model = rand_forest(mtry = tune(), min_n = tune(), trees = 100) %>% #add tuning of mtry and min_n parameters
  #setting trees to 100 here should also speed things up a bit, but more trees might be better
  set_engine("ranger", importance = "permutation") %>% #added importance metric
  set_mode("classification")

Nicotine_wflow = 
  workflow() %>% 
  add_model(rf_model) %>% 
  add_recipe(Nicotine_recipe)

rf_grid = grid_regular(
  mtry(range = c(2, 8)), #these values determined through significant trial and error
  min_n(range = c(5, 20)), #these values determined through significant trial and error
  levels = 10
)

set.seed(123)
rf_res_tuned = tune_grid(
  Nicotine_wflow,
  resamples = rf_folds,
  grid = rf_grid #use the tuning grid
)
```

#Visualization of relationship between parameters and performance metrics
```{r}
rf_res_tuned %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "Accuracy")
```
Alternative way to view
```{r}
rf_res_tuned %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  mutate(min_n = factor(min_n)) %>%
  ggplot(aes(mtry, mean, color = min_n)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "Accuracy")
```
Highest Accuracy is .730

#Question 6
Use the best mtry and min_n values from Question 5 to finalize the workflow and fit the modelto training set. Examine variable importance
```{r}
best_rf = select_best(rf_res_tuned, metric =  "accuracy")

final_rf = finalize_workflow(
  Nicotine_wflow,
  best_rf
)

final_rf
```
#fit the modelto training set
```{r}
#fit the finalized workflow to our training data
final_rf_fit = fit(final_rf, train)
```

#Examine variable importance
```{r}
final_rf_fit %>% pull_workflow_fit() %>% vip(geom = "point")
```
#which varibale is most important?
**SS**

#Question 7
To four decimal places, what is the accuracy of your model on the training set?
Preditions 
```{r}
trainpredrf = predict(final_rf_fit, train)
head(trainpredrf)
```

Confusion Matrix
```{r}
confusionMatrix(trainpredrf$.pred_class, train$Nicotine, 
                positive = "Yes")
```
#.9067

#question 8
.6707

#Question 9
To four decimal places, what is your model’s accuracy on the testing set?
```{r}
testpredrf = predict(final_rf_fit, test)
head(testpredrf)

confusionMatrix(testpredrf$.pred_class, test$Nicotine, 
                positive = "Yes")

```
**.7002**

#Question 10
Overfitting is likely occurring 